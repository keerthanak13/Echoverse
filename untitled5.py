# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMyMyejMvgEylEsqDOUtqCyMvQJioIc2
"""

# EchoVerse - Google Colab Implementation
# Install required packages
!pip install gradio transformers torch torchaudio accelerate gtts pydub

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from gtts import gTTS
import tempfile
import os

# Load Granite model for text processing
granite_model_name = "ibm-granite/granite-3.2-2b-instruct"
granite_tokenizer = AutoTokenizer.from_pretrained(granite_model_name)
granite_model = AutoModelForCausalLM.from_pretrained(granite_model_name, torch_dtype=torch.float16)

# Set pad token for granite tokenizer
if granite_tokenizer.pad_token is None:
    granite_tokenizer.pad_token = granite_tokenizer.eos_token

def process_text_with_granite(text, task="explain"):
    """Process text using Granite model"""
    if task == "translate":
        prompt = f"Translate the following text to English and make it conversational:\n{text}\n\nTranslation:"
    else:  # explain
        prompt = f"Explain the following text in a clear, engaging way:\n{text}\n\nExplanation:"

    # Truncate input if too long
    inputs = granite_tokenizer(
        prompt,
        return_tensors="pt",
        truncation=True,
        max_length=400,  # Reduced to leave room for generation
        padding=True
    )

    with torch.no_grad():
        outputs = granite_model.generate(
            inputs.input_ids,
            attention_mask=inputs.attention_mask,
            max_new_tokens=150,  # Reduced to stay within limits
            temperature=0.7,
            do_sample=True,
            pad_token_id=granite_tokenizer.pad_token_id
        )

    response = granite_tokenizer.decode(outputs[0], skip_special_tokens=True)
    # Extract only the generated part
    processed_text = response.split(prompt)[-1].strip()

    return processed_text

def text_to_speech(text):
    """Convert text to speech using Google TTS"""
    try:
        # Truncate text if too long
        if len(text) > 500:
            text = text[:500] + "..."

        # Create TTS object
        tts = gTTS(text=text, lang='en', slow=False)

        # Save to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
            tts.save(tmp_file.name)
            return tmp_file.name

    except Exception as e:
        print(f"TTS Error: {e}")
        return None

def echoverse_pipeline(input_text, task_type):
    """Main pipeline: Process text and convert to speech"""
    if not input_text.strip():
        return "Please enter some text", None

    # Step 1: Process with Granite
    processed_text = process_text_with_granite(input_text, task_type)

    # Step 2: Convert to speech
    audio_file = text_to_speech(processed_text)

    return processed_text, audio_file

# Gradio Interface
with gr.Blocks(title="üéß EchoVerse", theme=gr.themes.Soft()) as app:
    gr.Markdown("# üéß EchoVerse")
    gr.Markdown("*AI-Powered Text Processing & Speech Generation*")

    with gr.Row():
        with gr.Column():
            input_text = gr.Textbox(
                label="Enter your text",
                placeholder="Type or paste text here...",
                lines=4
            )

            task_type = gr.Radio(
                choices=["explain", "translate"],
                label="Choose task",
                value="explain"
            )

            submit_btn = gr.Button("üéôÔ∏è Generate Audio", variant="primary")

        with gr.Column():
            output_text = gr.Textbox(
                label="Processed Text",
                lines=6,
                interactive=False
            )

            output_audio = gr.Audio(
                label="Generated Speech",
                type="filepath"
            )

    submit_btn.click(
        fn=echoverse_pipeline,
        inputs=[input_text, task_type],
        outputs=[output_text, output_audio]
    )

    # Example inputs
    gr.Examples(
        examples=[
            ["The mitochondria is the powerhouse of the cell", "explain"],
            ["Bonjour, comment allez-vous?", "translate"],
            ["Machine learning is a subset of artificial intelligence", "explain"]
        ],
        inputs=[input_text, task_type]
    )

# Launch the app
if __name__ == "__main__":
    app.launch(debug=True, share=True)